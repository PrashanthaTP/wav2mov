# [![website](https://img.shields.io/static/v1?label=&message=wav2mov&color=blue&style=for-the-badge)](https://wav2mov.vercel.app)

##  Speech To Facial Animation Using GANs


[![python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/) [![pytorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=PyTorch&logoColor=white)](https://pytorch.org/) [![GANs](https://img.shields.io/badge/GANs-4BB749?style=for-the-badge&logo=Private-Internet-Access&logoColor=white)](#1)

This repo contains the pytorch implementation of achieving facial animation from given face image and speech input using Generative Adversarial Nets [[1]](#1).
## References

<a id="1" href="https://arxiv.org/abs/1406.2661">[1] Generative Adversarial Nets</a>
```
@article{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.2661},
  year={2014}
}
```

<a id=#2 href="https://link.springer.com/article/10.1007/s11263-019-01251-8">[2] Realistic Facial Animation using GANs</a>

[![Github stars](https://img.shields.io/badge/Github-sda-<COLOR>.svg)](https://github.com/DinoMan/speech-driven-animation)

``` 
@article{Vougioukas_2019,
	doi = {10.1007/s11263-019-01251-8},
	url = {https://doi.org/10.1007%2Fs11263-019-01251-8},
	year = 2019,
	month = {oct},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {128},
	number = {5},
	pages = {1398--1413},
	author = {Konstantinos Vougioukas and Stavros Petridis and Maja Pantic},
	title = {Realistic Speech-Driven Facial Animation with {GANs}},
	journal = {International Journal of Computer Vision}
}
```

<a id="#3" href="https://arxiv.org/abs/1805.09313">[3] End to End Facial Animation using Temporal GANs</a>
```
@article{vougioukas2018end,
  title={End-to-end speech-driven facial animation with temporal gans},
  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},
  journal={arXiv preprint arXiv:1805.09313},
  year={2018}
}
```

<a id="#4" href="https://arxiv.org/abs/2008.10010">[4] A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild</a>


[![Github stars](https://img.shields.io/badge/Github-wav2Lip-<COLOR>.svg)](https://github.com/Rudrabha/Wav2Lip)
```
@inproceedings{10.1145/3394171.3413532,
author = {Prajwal, K R and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P. and Jawahar, C.V.},
title = {A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413532},
doi = {10.1145/3394171.3413532},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {484â€“492},
numpages = {9},
keywords = {lip sync, talking face generation, video generation},
location = {Seattle, WA, USA},
series = {MM '20}
}
```
