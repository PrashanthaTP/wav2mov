{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StridedAudio:\n",
    "    def __init__(self,stride,coarticulation_factor=0):\n",
    "        self.coarticulation_factor = coarticulation_factor \n",
    "        self.stride = stride \n",
    "        if isinstance(self.stride,float):\n",
    "            self.stride = math.floor(self.stride)\n",
    "        \n",
    "    \n",
    "    def get_frame_wrapper(self,audio):\n",
    "        # padding = torch.tensor([])\n",
    "        # audio = torch.from_numpy(audio)\n",
    "        \n",
    "        if self.coarticulation_factor!=0:\n",
    "            padding = torch.cat([torch.tensor([0]*self.stride) for _ in range(self.coarticulation_factor)],dim=0)\n",
    "            audio = torch.cat([padding,audio,padding])\n",
    "            \n",
    "            audio = audio.unsqueeze(0)\n",
    "            \n",
    "        def get_frame(idx):\n",
    "            center_frame_pos = idx*self.stride\n",
    "            # print(center_frame_pos)\n",
    "            center_frame = audio[:,center_frame_pos:center_frame_pos+self.stride]\n",
    "            if self.coarticulation_factor == 0:\n",
    "                return center_frame, center_frame_pos+self.stride\n",
    "            # curr_idx = center_frame_pos\n",
    "            # print(f'audio shape {audio.shape} centerframe {center_frame.shape}')\n",
    "            for i in range(self.coarticulation_factor):\n",
    "                center_frame = torch.cat([audio[:,center_frame_pos-(i-1)*self.stride:center_frame_pos-i*self.stride],center_frame],dim=1)\n",
    "            last_pos = 0\n",
    "            for i in range(self.coarticulation_factor):\n",
    "                center_frame = torch.cat([audio[:,center_frame_pos+(i+1)*self.stride:center_frame_pos+(i+2)*self.stride]])\n",
    "                last_pos = center_frame_pos+(i+2)*self.stride\n",
    "            return center_frame,last_pos\n",
    "        return get_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}