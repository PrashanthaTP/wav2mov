{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.functional import Tensor\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iwav2mov.core.models.base_model import BaseModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU : Sequence of Frames\n",
    "class SequenceDiscriminator(BaseModel):\n",
    "    \"\"\"\n",
    "    >>>  self.gru = nn.GRU(input_size=in_size,hidden_size=h_size,num_layers=num_layers,batch_first = True)\n",
    "    >>> out,_ = self.gru(x)#out is of shape (batch_size,seq_len,num_dir*hidden_dim)\n",
    "    >>> return out[:,-1,:]\n",
    "    \"\"\"\n",
    "    def __init__(self,hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams \n",
    "        in_size, h_size, num_layers = self.hparams['in_size'],self.hparams['h_size'],self.hparams['num_layers']\n",
    "        self.gru = nn.GRU(input_size=in_size,hidden_size=h_size,num_layers=num_layers,batch_first = True)\n",
    "      \n",
    "    def forward(self,x1,x2):\n",
    "        # x1 and x2 are of shape (batch_size,in_channels.img_size,img_size)\n",
    "        \"\"\" \n",
    "        For GRU  the input should be 3 dimensional \n",
    "        (batch_size,seq_len,num_features) #assuming batch_first is set to True while initializing GRU\n",
    "        so flatten x1 and x2 which are 3 dimensional images and are thus 5 dimensional tensors after batching\n",
    "        and catenate to get the shape (batch_size,2,num_channels*img_size*img_size)\n",
    "        \"\"\"\n",
    "        batch_size = x1.shape[0]\n",
    "        # print(x1.shape,self.hparams['in_channels'],x1.reshape(batch_size,1,-1).shape)\n",
    "        x1 = torch.reshape(x1,(batch_size,self.hparams['in_channels'],-1))\n",
    "        x2 = torch.reshape(x2,(batch_size,self.hparams['in_channels'],-1))\n",
    "        # print(x1.shape,x2.shape)\n",
    "        x1 = torch.cat([x1,x2],dim=1)\n",
    "        # print(x1.shape)\n",
    "        out,_ = self.gru(x1)#out is of shape (batch_size,seq_len,num_dir*hidden_dim)\n",
    "        \n",
    "        return out[:,-1,:]\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams['lr'], betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SequenceDiscriminatorCNN(BaseModel):\n",
    "\n",
    "    def __init__(self,hparams,use_bias=True):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.in_channels = hparams['in_channels']\n",
    "        self.chs = hparams['chs']\n",
    "        chs = [self.in_channels] + self.chs\n",
    "        self.cnn = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv3d(chs[i], chs[i+1], (3,4,4), (1,2,2),(1,1,1),bias=use_bias),\n",
    "                        #   nn.BatchNorm3d(chs[i+1]),\n",
    "                          nn.LeakyReLU(0.2) ) for i in range(len(chs)-2)\n",
    "            ])\n",
    "        self.cnn.append(nn.Conv3d(chs[-2], chs[-1], (2, 4, 4), (2, 2, 2), (1, 1, 1)))\n",
    "        \n",
    "        \"\"\"\n",
    "        [8,64,128,256,1],\n",
    "                    in          out\n",
    "        filter 1 : 2x256x256  | ((2-2)+2)/2 +1 = 2\n",
    "                                ((256-4+2)/2) + 1 = \n",
    "                                \n",
    "                    20x256x256 | 20-3+2/1 + 1 = 20\n",
    "        \"\"\" \n",
    "    def forward(self,*x):\n",
    "        \"\"\"sequence discriminator using 3d convolution for spatio temporal feature extraction\n",
    "\n",
    "\n",
    "\n",
    "        Args:\n",
    "            x1 (Tensor): prev frame : shape = (N,num_channels,img_size,img_size)\n",
    "            x2 (Tensor): curr frame : shape = (N,num_channels,img_size,img_size)\n",
    "        \"\"\"\n",
    "      \n",
    "        if len(x)==1 and isinstance(x[0],Tensor):\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat([frame.unsqueeze(dim=2) for frame in x if frame.dim()==4 ],dim=2)\n",
    "            \n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "      \n",
    "        for cnn in self.cnn:\n",
    "            x = cnn(x)\n",
    "            # print(f'out shape : {x1.shape}')\n",
    "        \n",
    "        return x.reshape(batch_size,-1)\n",
    "        \n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams['lr'], betas=(0.5,0.999))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}