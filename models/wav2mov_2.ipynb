{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from torch.cuda import amp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iwav2mov.core.models.template import TemplateModel\n",
    "from iwav2mov.models.generator import Generator, GeneratorBW\n",
    "from iwav2mov.models.sequence_discriminator import SequenceDiscriminator, SequenceDiscriminatorCNN\n",
    "from iwav2mov.models.identity_discriminator import IdentityDiscriminator\n",
    "from iwav2mov.models.patch_disc import PatchDiscriminator\n",
    "from iwav2mov.models.sync_discriminator import SyncDiscriminator\n",
    "from iwav2mov.models.utils import init_net\n",
    "from iwav2mov.losses.gan_loss import GANLoss\n",
    "from iwav2mov.losses.l1_loss import L1_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Wav2Mov(nn.Module):\n",
    "    def __init__(self, config, hparams, logger):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hparams = hparams\n",
    "        self.logger = logger\n",
    "\n",
    "        self.gen = Generator(hparams['gen'])\n",
    "        self.seq_disc = SequenceDiscriminator(hparams['disc']['sequence'])\n",
    "        self.id_disc = PatchDiscriminator(hparams['disc']['patch_disc'])\n",
    "        # self.id_disc = IdentityDiscriminator(hparams['disc']['identity'])\n",
    "        self.sync_disc = SyncDiscriminator(hparams['disc']['sync'])\n",
    "\n",
    "        self.scaler = amp.GradScaler()\n",
    "\n",
    "    def forward(self, speech, face_image):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Wav2MovBW(TemplateModel):\n",
    "    def __init__(self, config, hparams, logger):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hparams = hparams\n",
    "        self.logger = logger\n",
    "        device = hparams['device']\n",
    "        if device == 'cuda':\n",
    "            device = 'cpu' if not torch.cuda.is_available() else device\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        self.gen = GeneratorBW(hparams['gen'])\n",
    "        self.seq_disc = SequenceDiscriminatorCNN(\n",
    "            hparams['disc']['sequence_disc_cnn'])\n",
    "        self.id_disc = PatchDiscriminator(hparams['disc']['patch_disc'])\n",
    "        # self.id_disc = IdentityDiscriminator(hparams['disc']['identity_disc'])\n",
    "        self.sync_disc = SyncDiscriminator(hparams['disc']['sync_disc'])\n",
    "\n",
    "        init_net(self.gen)\n",
    "        init_net(self.seq_disc)\n",
    "        init_net(self.id_disc)\n",
    "        init_net(self.sync_disc)\n",
    "\n",
    "        self.optim_gen = self.gen.get_optimizer()\n",
    "        self.optim_seq_disc = self.seq_disc.get_optimizer()\n",
    "        self.optim_id_disc = self.id_disc.get_optimizer()\n",
    "        self.optim_sync_disc = self.sync_disc.get_optimizer()\n",
    "\n",
    "        self.criterion_gan = GANLoss(self.device)\n",
    "        self.criterion_L1 = L1_Loss()\n",
    "\n",
    "        self.scaler = amp.GradScaler()\n",
    "\n",
    "        self.mode = None\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        # self.prev_fake_video_frame = self.curr_fake_video_frame\n",
    "        self.curr_fake_video_frame = self.gen(self.curr_real_audio_frame, self.still_image)\n",
    "        # print('gen : train_mode : ',self.gen.training)\n",
    "        if self.gen.training:\n",
    "            self.fake_frames = torch.cat([self.fake_frames,self.curr_fake_video_frame.detach().unsqueeze(2)],dim=2) \\\n",
    "                                    if self.fake_frames is not None else self.curr_fake_video_frame.detach().unsqueeze(dim=2)\n",
    "            # print(f'added to frame to fake_frames : {len(self.fake_frames)},{self.fake_frames.shape}')\n",
    "    def _set_frame_history(self):\n",
    "        self.real_frames = None\n",
    "        self.fake_frames = None\n",
    "\n",
    "        self.curr_real_video_frame = None\n",
    "        self.curr_real_audio_frame = None\n",
    "\n",
    "        self.curr_fake_video_frame = None\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self._set_frame_history()\n",
    "        self.to(self.device)\n",
    "        self.gen.train()\n",
    "        self.id_disc.train()\n",
    "        self.seq_disc.train()\n",
    "        self.sync_disc.train()\n",
    "\n",
    "\n",
    "    def set_condition(self, still_image):\n",
    "        self.still_image = still_image.to(self.device)\n",
    "\n",
    "    def set_input(self, audio_frame, video_frame):\n",
    "\n",
    "        self.curr_real_video_frame = video_frame.to(self.device)\n",
    "        self.curr_real_audio_frame = audio_frame.to(self.device)\n",
    "        self.real_frames = torch.cat([self.real_frames, self.curr_real_video_frame.detach().unsqueeze(2)], dim=2) \\\n",
    "                                    if self.real_frames is not None else self.curr_real_video_frame.detach().unsqueeze(dim=2)\n",
    "                                    \n",
    "        # print(f'added to frame to real_frames : {len(self.real_frames)}')\n",
    "    def backward_gen(self):\n",
    "        \"\"\"requires <curr_fake_frame> to be populated before hand that is during discriminator training\n",
    "        \"\"\"\n",
    "        with amp.autocast():\n",
    "            sync_disc_out = self.sync_disc(self.curr_real_audio_frame,\n",
    "                                           self.curr_fake_video_frame)\n",
    "\n",
    "            gen_loss = self.criterion_gan(sync_disc_out,\n",
    "                                          is_real_target=True)*self.hparams['scales']['lambda_sync_disc']\n",
    "\n",
    "  \n",
    "\n",
    "            id_disc_out = self.id_disc(self.curr_fake_video_frame,\n",
    "                                       self.still_image)\n",
    "\n",
    "            gen_loss += self.criterion_gan(id_disc_out,\n",
    "                                           is_real_target=True) * self.hparams['scales']['lambda_id_disc']\n",
    "\n",
    "            gen_loss += self.criterion_L1(self.curr_fake_video_frame,\n",
    "                                          self.curr_real_video_frame)*self.hparams['scales']['lambda_L1']\n",
    "\n",
    "        self.scaler.scale(gen_loss).backward()\n",
    "        return gen_loss.item()\n",
    "    \n",
    "    def backward_gen_seq(self):\n",
    "        \n",
    "        with amp.autocast():\n",
    "            seq_disc_out = self.seq_disc(self.fake_frames)\n",
    "            gen_seq_loss = self.criterion_gan(seq_disc_out,is_real_target=True)*self.hparams['scales']['lambda_seq_disc']\n",
    "        self.scaler.scale(gen_seq_loss).backward()\n",
    "        return gen_seq_loss.item()\n",
    "        \n",
    "    def backward_sync_disc(self):\n",
    "        # print(self.curr_real_video_frame.shape)\n",
    "        with amp.autocast():\n",
    "            disc_out = self.sync_disc(\n",
    "                self.curr_real_audio_frame, self.curr_real_video_frame)\n",
    "            loss_d = self.criterion_gan(disc_out, is_real_target=True)\n",
    "            disc_out = self.sync_disc(\n",
    "                self.curr_real_audio_frame, self.curr_fake_video_frame.detach())\n",
    "            loss_d += self.criterion_gan(disc_out, is_real_target=False)\n",
    "            loss_d /= 2\n",
    "        self.scaler.scale(loss_d).backward()\n",
    "        return loss_d.item()\n",
    "\n",
    "    def backward_seq_disc(self):\n",
    "        with amp.autocast():\n",
    "            disc_out = self.seq_disc(self.real_frames)\n",
    "            loss_d = self.criterion_gan(disc_out, is_real_target=True)\n",
    "            disc_out = self.seq_disc(self.fake_frames)\n",
    "            loss_d += self.criterion_gan(disc_out, is_real_target=False)\n",
    "            loss_d /= 2\n",
    "\n",
    "        self.scaler.scale(loss_d).backward()\n",
    "        return loss_d.item()\n",
    "    \n",
    "    def backward_id_disc(self):\n",
    "        with amp.autocast():\n",
    "            disc_out = self.id_disc(\n",
    "                self.curr_real_video_frame, self.still_image)\n",
    "            loss_d = self.criterion_gan(disc_out, is_real_target=True)\n",
    "            disc_out = self.id_disc(\n",
    "                self.curr_fake_video_frame.detach(), self.still_image)\n",
    "            loss_d += self.criterion_gan(disc_out, is_real_target=False)\n",
    "            loss_d /= 2\n",
    "        self.scaler.scale(loss_d).backward()\n",
    "        return loss_d.item()\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        losses = {}\n",
    "        with amp.autocast():\n",
    "            self.forward()  # generate fake frame\n",
    "      \n",
    "        self.optim_sync_disc.zero_grad()\n",
    "        losses['sync_disc'] = self.backward_sync_disc()\n",
    "        self.scaler.step(self.optim_sync_disc)\n",
    "\n",
    "        self.optim_id_disc.zero_grad()\n",
    "        losses['id_disc'] = self.backward_id_disc()\n",
    "        self.scaler.step(self.optim_id_disc)\n",
    "\n",
    "        self.optim_gen.zero_grad()\n",
    "        losses['gen'] = self.backward_gen()\n",
    "        self.scaler.step(self.optim_gen)\n",
    "\n",
    "        self.scaler.update()\n",
    "        return losses\n",
    "\n",
    "    def optimize_sequence(self):\n",
    "        losses = {}\n",
    "        randpos = 5\n",
    "        # randpos = random.randint(0,self.real_frames.shape[2]-5)\n",
    "        self.real_frames = self.real_frames[...,randpos:randpos+20,:,:]\n",
    "        self.fake_frames = self.fake_frames[...,randpos:randpos+20,:,:]\n",
    "        losses['seq_disc'] = self.backward_seq_disc()\n",
    "        losses['gen'] = self.backward_gen_seq()\n",
    "        return losses\n",
    "        \n",
    "    def save(self,epoch=0):\n",
    "        torch.save({'state_dict':self.gen.state_dict(),'epoch':epoch},\n",
    "                   self.config['gen_checkpoint_fullpath'])\n",
    "        torch.save({'state_dict':self.seq_disc.state_dict(),'epoch':epoch},\n",
    "                   self.config['seq_disc_checkpoint_fullpath'])\n",
    "        torch.save({'state_dict':self.sync_disc.state_dict(),'epoch':epoch},\n",
    "                   self.config['sync_disc_checkpoint_fullpath'])\n",
    "        torch.save({'state_dict':self.id_disc.state_dict(),'epoch':epoch},\n",
    "                   self.config['id_disc_checkpoint_fullpath'])\n",
    "        \n",
    "    def load(self,checkpoint_dir):\n",
    "        checkpoint = os.path.basename(checkpoint_dir)\n",
    "        pt_file = checkpoint_dir + '\\\\%(model_name)s_'+checkpoint+'.pt'\n",
    "        try:\n",
    "            self.gen.load_state_dict(torch.load(pt_file%{'model_name':'gen'})['state_dict'])\n",
    "            self.sync_disc.load_state_dict(torch.load(pt_file%{'model_name':'sync_disc'})['state_dict'])\n",
    "            self.seq_disc.load_state_dict(torch.load(pt_file%{'model_name':'seq_disc'})['state_dict'])\n",
    "            self.id_disc.load_state_dict(torch.load(pt_file%{'model_name':'id_disc'})['state_dict'])\n",
    "            \n",
    "            return torch.load(pt_file % {'model_name': 'gen'})['epoch']\n",
    "        except Exception as e:\n",
    "            self.logger.exception(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}