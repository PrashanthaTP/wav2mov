{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    \"\"\" \n",
    "    ref : https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py\n",
    "    \"\"\"\n",
    "    def __init__(self,hparams,norm_layer=nn.BatchNorm2d,use_bias = True):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        input_nc = hparams['in_channels']\n",
    "        ndf = hparams['ndf']\n",
    "        n_layers = hparams['num_layers']\n",
    "        # use_bias = norm_layer==nn.InstanceNorm2d\n",
    "        #batch normalization has affine = True so it has additional scaling and biasing/shifting terms by default.\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc*2,ndf,kw,2,padw),\n",
    "                    nn.LeakyReLU(0.2,inplace=True)]#inplace=True saves memory \n",
    "        \n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        \n",
    "        for n in range(1,n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2**n,8) #multiplier is clipped at 8 : so if ndf is 64 max possible is 64*8=512\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf*nf_mult_prev,ndf*nf_mult,kw,2,padw,bias=use_bias),\n",
    "                # norm_layer(ndf*nf_mult),\n",
    "                nn.LeakyReLU(0.2,True)      \n",
    "                ]\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2**n_layers,8)\n",
    "        sequence += [ \n",
    "                     nn.Conv2d(ndf*nf_mult_prev,ndf*nf_mult,kw,1,padw,bias=use_bias),\n",
    "                    #  norm_layer(ndf*nf_mult),\n",
    "                     nn.LeakyReLU(0.2,True)\n",
    "                     ]\n",
    "        \n",
    "        sequence += [\n",
    "                nn.Conv2d(ndf*nf_mult,1,kw,1,padw)\n",
    "            ]\n",
    "        \n",
    "        self.disc = nn.Sequential(*sequence)\n",
    "        \n",
    "    def forward(self,frame_image,still_image):\n",
    "        frame_image = torch.cat([frame_image,still_image],dim=1)#catenate images along the channel dimension\n",
    "        #frame image now has a shape of (N,C+C,H,W)\n",
    "        return self.disc(frame_image)\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams['lr'], betas=(0.5, 0.999))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
